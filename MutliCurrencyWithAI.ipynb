{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0f55fc82-4743-4142-8642-9f9bd181540c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.105.0\n  Downloading openai-1.105.0-py3-none-any.whl.metadata (29 kB)\nCollecting pymupdf>=1.24.0\n  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_aarch64.whl.metadata (3.4 kB)\nRequirement already satisfied: pillow in /databricks/python3/lib/python3.12/site-packages (10.3.0)\nCollecting pillow\n  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (9.0 kB)\nCollecting pytesseract>=0.3.10\n  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\nCollecting jsonschema>=4.22.0\n  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.12/site-packages (from openai==1.105.0) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.105.0) (1.9.0)\nCollecting httpx<1,>=0.23.0 (from openai==1.105.0)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting jiter<1,>=0.4.0 (from openai==1.105.0)\n  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from openai==1.105.0) (2.8.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai==1.105.0) (1.3.0)\nCollecting tqdm>4 (from openai==1.105.0)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /databricks/python3/lib/python3.12/site-packages (from openai==1.105.0) (4.11.0)\nRequirement already satisfied: packaging>=21.3 in /databricks/python3/lib/python3.12/site-packages (from pytesseract>=0.3.10) (24.1)\nCollecting attrs>=22.2.0 (from jsonschema>=4.22.0)\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.22.0)\n  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting referencing>=0.28.4 (from jsonschema>=4.22.0)\n  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py>=0.7.1 (from jsonschema>=4.22.0)\n  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.2 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai==1.105.0) (3.7)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai==1.105.0) (2024.6.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.105.0)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.105.0)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.105.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai==1.105.0) (2.20.1)\nDownloading openai-1.105.0-py3-none-any.whl (928 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/928.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m928.2/928.2 kB\u001B[0m \u001B[31m24.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_aarch64.whl (23.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/23.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m23.3/23.5 MB\u001B[0m \u001B[31m130.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.5/23.5 MB\u001B[0m \u001B[31m97.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/6.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m85.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\nDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\nDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\nDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (345 kB)\nDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\nDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\nDownloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (385 kB)\nDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nInstalling collected packages: tqdm, rpds-py, pymupdf, pillow, jiter, h11, attrs, referencing, pytesseract, httpcore, jsonschema-specifications, httpx, openai, jsonschema\n  Attempting uninstall: pillow\n    Found existing installation: pillow 10.3.0\n    Not uninstalling pillow at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cc0965a5-7ec5-44cc-a64a-99f814f4085b\n    Can't uninstall 'pillow'. No files were found to uninstall.\n  Attempting uninstall: h11\n    Found existing installation: h11 0.14.0\n    Not uninstalling h11 at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cc0965a5-7ec5-44cc-a64a-99f814f4085b\n    Can't uninstall 'h11'. No files were found to uninstall.\nSuccessfully installed attrs-25.3.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 openai-1.105.0 pillow-11.3.0 pymupdf-1.26.4 pytesseract-0.3.13 referencing-0.36.2 rpds-py-0.27.1 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade \"openai==1.105.0\" \"pymupdf>=1.24.0\" pillow \"pytesseract>=0.3.10\" \"jsonschema>=4.22.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd982c72-eec5-4b02-a269-c81a956df498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "367e3bde-3355-40e2-a712-cfc23414cb1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==== CONFIG ====\n",
    "USE_OCR  = True           # Use OCR for scanned/blurry PDFs\n",
    "OCR_DPI  = 600            # High DPI improves OCR quality\n",
    "OCR_LANG = \"eng\"          # Add languages if needed, e.g. \"eng+ara\"\n",
    "MODEL    = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "import os, json, re, io, base64\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "from jsonschema import Draft202012Validator\n",
    "\n",
    "# --- API KEY (choose ONE of the two approaches) ---\n",
    "try:\n",
    "    # Enterprise workspace with Secrets\n",
    "    OPENAI_API_KEY = dbutils.secrets.get(scope=\"kv\", key=\"openai-api-key\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "except Exception:\n",
    "    # Community Edition (uncomment and paste your key)\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxx\"\n",
    "    pass\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ==== TARGET JSON SCHEMA (your required output) ====\n",
    "structured_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"sections\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"additionalProperties\": False,\n",
    "                \"properties\": {\n",
    "                    \"section\": {\"type\": \"string\"},  # Statement number e.g. \"211\"\n",
    "                    \"OpeningBalance\": {\"type\": [\"string\",\"null\"]},\n",
    "                    \"ClosingBalance\": {\"type\": [\"string\",\"null\"]},\n",
    "                    \"EndOfDayInformation\": {\"type\": [\"string\",\"null\"]},\n",
    "                    \"Transactions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"additionalProperties\": False,\n",
    "                            \"properties\": {\n",
    "                                \"ValueDate\":    {\"type\": [\"string\",\"null\"]},\n",
    "                                \"BookedDate\":   {\"type\": [\"string\",\"null\"]},\n",
    "                                \"CounterParty\": {\"type\": [\"string\",\"null\"]},\n",
    "                                \"Amount\":       {\"type\": [\"string\",\"null\"]}\n",
    "                            },\n",
    "                            \"required\": [\"ValueDate\",\"BookedDate\",\"CounterParty\",\"Amount\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"BankReference\":   {\"type\": [\"string\",\"null\"]},\n",
    "                    \"TransactionType\": {\"type\": [\"string\",\"null\"]}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"section\",\n",
    "                    \"OpeningBalance\",\n",
    "                    \"ClosingBalance\",\n",
    "                    \"EndOfDayInformation\",\n",
    "                    \"Transactions\",\n",
    "                    \"BankReference\",\n",
    "                    \"TransactionType\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"sections\"]\n",
    "}\n",
    "validator = Draft202012Validator(structured_schema)\n",
    "\n",
    "# ==== PDF TEXT & OCR ====\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def _norm_spaces(s: str) -> str:\n",
    "    s = (s or \"\")\n",
    "    s = s.replace(\"\\u00A0\",\" \").replace(\"\\u2009\",\" \")\n",
    "    s = s.replace(\"\\u2013\",\"-\").replace(\"\\u2014\",\"-\").replace(\"\\u2212\",\"-\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\r\\n?\",\"\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def get_text_native(path: str, max_pages=300) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    parts=[]\n",
    "    for i,p in enumerate(doc):\n",
    "        if i>=max_pages: break\n",
    "        parts.append(p.get_text(\"text\", sort=True) or \"\")\n",
    "    doc.close()\n",
    "    return _norm_spaces(\"\\n\".join(parts))\n",
    "\n",
    "def get_text_ocr(path: str, dpi=OCR_DPI, max_pages=300, lang=OCR_LANG) -> str:\n",
    "    import pytesseract\n",
    "    doc = fitz.open(path)\n",
    "    parts=[]\n",
    "    scale = dpi/72.0\n",
    "    matrix = fitz.Matrix(scale, scale)\n",
    "    for i,p in enumerate(doc):\n",
    "        if i>=max_pages: break\n",
    "        pix = p.get_pixmap(matrix=matrix, alpha=False)\n",
    "        png = pix.tobytes(\"png\")\n",
    "        img = Image.open(io.BytesIO(png)).convert(\"L\")\n",
    "        img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "        img = ImageEnhance.Sharpness(img).enhance(1.6)\n",
    "        txt = pytesseract.image_to_string(img, lang=lang) or \"\"\n",
    "        parts.append(txt)\n",
    "    doc.close()\n",
    "    return _norm_spaces(\"\\n\".join(parts))\n",
    "\n",
    "def render_pages_as_data_urls(path: str, dpi=OCR_DPI, max_pages=60) -> List[str]:\n",
    "    doc = fitz.open(path)\n",
    "    urls=[]\n",
    "    scale=dpi/72.0\n",
    "    matrix=fitz.Matrix(scale,scale)\n",
    "    for i,p in enumerate(doc):\n",
    "        if i>=max_pages: break\n",
    "        pix=p.get_pixmap(matrix=matrix, alpha=False)\n",
    "        png=pix.tobytes(\"png\")\n",
    "        b64=base64.b64encode(png).decode(\"utf-8\")\n",
    "        urls.append(\"data:image/png;base64,\"+b64)\n",
    "    doc.close()\n",
    "    return urls\n",
    "\n",
    "# ==== Minimal seed for model context ====\n",
    "def build_seed(_: str) -> dict:\n",
    "    # Keep minimal; the system prompt enforces final structure\n",
    "    return {\"sections\": []}\n",
    "\n",
    "# ==== Post-processing to enforce CounterParty = null when blank ====\n",
    "NULLISH_TOKENS = {\"\", \"-\", \"—\", \"n/a\", \"na\", \"none\", \"null\", \"<undefined>\", \"<unknown>\"}\n",
    "\n",
    "def _null_if_blank(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    return None if s.lower() in NULLISH_TOKENS else (s if s else None)\n",
    "\n",
    "def enforce_counterparty_none(doc: dict) -> dict:\n",
    "    if not isinstance(doc, dict):\n",
    "        return doc\n",
    "    sections = doc.get(\"sections\", [])\n",
    "    for sec in sections:\n",
    "        txns = sec.get(\"Transactions\", [])\n",
    "        for t in txns:\n",
    "            for k in (\"ValueDate\", \"BookedDate\", \"CounterParty\", \"Amount\"):\n",
    "                t[k] = _null_if_blank(t.get(k))\n",
    "            if t.get(\"CounterParty\") is None:\n",
    "                t[\"CounterParty\"] = None\n",
    "    return doc\n",
    "\n",
    "# ==== NEW: precise fix for missing ValueDate / BookedDate ====\n",
    "# We use OCR/native text to find labelled dates within each statement section’s text segment.\n",
    "DATE_RE = r\"\\b(?:0[1-9]|[12][0-9]|3[01])[\\/\\-.](?:0[1-9]|1[0-2])[\\/\\-.](?:\\d{2}|\\d{4})\\b\"\n",
    "VALUE_LABELS  = r\"(?:value\\s*date|valuedate|value\\s*dt|val(?:\\.|\\s*)date)\"\n",
    "BOOKED_LABELS = r\"(?:booked\\s*date|booking\\s*date|book\\s*date|posting\\s*date|posted\\s*date|booked\\s*dt|posting\\s*dt)\"\n",
    "\n",
    "def _find_labeled_date(ctx: str, label_regex: str) -> Optional[str]:\n",
    "    # Look forward of the label for up to 50 non-digit chars, then a date\n",
    "    m = re.search(rf\"{label_regex}[^0-9]{{0,50}}({DATE_RE})\", ctx, flags=re.I)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def _section_context_slices(full_text: str, section_ids: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Build a text slice per section using an anchor like: 'Statement number 211'\n",
    "    Fallback to raw number if needed. Non-overlapping & ordered.\n",
    "    \"\"\"\n",
    "    anchors = []\n",
    "    for sid in section_ids:\n",
    "        # prefer explicit 'statement' anchor\n",
    "        pat = rf\"statement\\s*(?:number|no\\.?|#)?\\s*[:\\-]?\\s*{re.escape(sid)}\"\n",
    "        m = re.search(pat, full_text, flags=re.I)\n",
    "        if not m:\n",
    "            # fallback: bare number (word boundary) – less precise but better than nothing\n",
    "            m = re.search(rf\"\\b{re.escape(sid)}\\b\", full_text)\n",
    "        if m:\n",
    "            anchors.append((m.start(), sid))\n",
    "    anchors.sort(key=lambda x: x[0])\n",
    "\n",
    "    # build slices\n",
    "    out = {}\n",
    "    for i, (start, sid) in enumerate(anchors):\n",
    "        end = anchors[i+1][0] if i+1 < len(anchors) else len(full_text)\n",
    "        out[sid] = full_text[start:end]\n",
    "    return out\n",
    "\n",
    "def fix_missing_tx_dates(doc: dict, full_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Only fill ValueDate/BookedDate when they are None, using labelled dates\n",
    "    found inside the text slice for that section. No other changes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sections = doc.get(\"sections\", [])\n",
    "        if not sections:\n",
    "            return doc\n",
    "        section_ids = [str(s.get(\"section\",\"\")).strip() for s in sections if s.get(\"section\")]\n",
    "        if not section_ids:\n",
    "            return doc\n",
    "\n",
    "        slices = _section_context_slices(full_text, section_ids)\n",
    "\n",
    "        for sec in sections:\n",
    "            sid = str(sec.get(\"section\",\"\")).strip()\n",
    "            ctx = slices.get(sid, \"\")\n",
    "            if not ctx:\n",
    "                continue\n",
    "\n",
    "            val_date  = _find_labeled_date(ctx, VALUE_LABELS)\n",
    "            book_date = _find_labeled_date(ctx, BOOKED_LABELS)\n",
    "\n",
    "            # Update only missing fields, leave existing values intact\n",
    "            for tx in (sec.get(\"Transactions\") or []):\n",
    "                if (tx.get(\"ValueDate\") is None) and val_date:\n",
    "                    tx[\"ValueDate\"] = val_date\n",
    "                if (tx.get(\"BookedDate\") is None) and book_date:\n",
    "                    tx[\"BookedDate\"] = book_date\n",
    "        return doc\n",
    "    except Exception:\n",
    "        # Defensive: never break the pipeline\n",
    "        return doc\n",
    "\n",
    "# ==== Strong system prompt: exact structure, keep duplicates ====\n",
    "JSON_ONLY_SYSTEM = (\n",
    "    \"You are an OCR + bank statement extraction agent. \"\n",
    "    \"You MUST NOT invent values. If a value is not present, set it to null. \"\n",
    "    \"Return ONLY one minified JSON object that VALIDATES against this schema: \"\n",
    "    + json.dumps(structured_schema) + \" \"\n",
    "    \"Do NOT deduplicate or merge. If the same Statement Number (section) appears multiple times, \"\n",
    "    \"create multiple section objects with the SAME 'section' value, in the exact order they appear in the PDF. \"\n",
    "    \"If any label/value pair or transaction row repeats, include each instance as-is (no collapsing). \"\n",
    "    \"Interpret 'section' as the Statement Number (e.g., '211', '210'). \"\n",
    "    \"For each occurrence of a statement number, produce ONE object with keys: \"\n",
    "    \"section, OpeningBalance, ClosingBalance, EndOfDayInformation, \"\n",
    "    \"Transactions (array of {ValueDate,BookedDate,CounterParty,Amount}), \"\n",
    "    \"BankReference, TransactionType. \"\n",
    "    \"When present, ALWAYS extract both 'ValueDate' and 'BookedDate' shown near transaction details \"\n",
    "    \"(e.g., lines like 'Value Date 30/07/25' and 'Booked/Posting Date 30/07/25'). \"\n",
    "    \"Use exactly the key names from the schema and do not include extra keys. \"\n",
    "    \"If CounterParty is missing for a transaction, set CounterParty to null. \"\n",
    "    \"Output JSON only (no commentary, no code fences).\"\n",
    ")\n",
    "\n",
    "def _validate_json(s: str) -> dict:\n",
    "    s = re.sub(r\"^```(?:json)?\\s*|\\s*```$\",\"\",s.strip(), flags=re.I|re.DOTALL)\n",
    "    obj = json.loads(s)\n",
    "    validator.validate(obj)\n",
    "    return obj\n",
    "\n",
    "def gpt4o_extract(pdf_path: str, ocr_text: str, seed_doc: dict) -> dict:\n",
    "    images = render_pages_as_data_urls(pdf_path, dpi=OCR_DPI)\n",
    "    ocr_chunk  = ocr_text[:120000]\n",
    "    seed_chunk = json.dumps(seed_doc)[:120000]\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": JSON_ONLY_SYSTEM\n",
    "    },{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            [{\"type\": \"input_text\", \"text\": \"Below is noisy OCR/native text:\\n\" + ocr_chunk}] +\n",
    "            [{\"type\": \"input_text\", \"text\": \"Here is a minimal seed JSON:\\n\" + seed_chunk}] +\n",
    "            [{\"type\": \"input_image\", \"image_url\": u} for u in images]\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    resp = client.responses.create(model=MODEL, input=messages, temperature=0)\n",
    "    return _validate_json(resp.output_text)\n",
    "\n",
    "# ==== Orchestrator (AI ONLY) ====\n",
    "def extract_structured_pdf(pdf_path: str, use_ocr=USE_OCR, dpi=OCR_DPI, lang=OCR_LANG) -> dict:\n",
    "    # Gather text (we’ll use it only to fix missing dates; no other changes)\n",
    "    text = get_text_ocr(pdf_path, dpi=dpi, lang=lang) if use_ocr else get_text_native(pdf_path)\n",
    "    seed = build_seed(text)\n",
    "    doc  = gpt4o_extract(pdf_path, text, seed)\n",
    "    doc  = enforce_counterparty_none(doc)   # keep your original normalization\n",
    "    doc  = fix_missing_tx_dates(doc, text)  # <<< ONLY change requested: fill Value/Booked dates when missing\n",
    "    return doc\n",
    "\n",
    "# ==== Example run (update path) ====\n",
    "# pdf_path = \"/mnt/data/YourStatement.pdf\"\n",
    "# result = extract_structured_pdf(pdf_path, use_ocr=True, dpi=600)\n",
    "# print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a75531f9-ec94-4553-852b-55ee4e4a649a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'sections': [{'section': '211',\n",
       "   'OpeningBalance': '30/07/25 0,00 AED',\n",
       "   'ClosingBalance': '30/07/25 0,00 AED',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '30/07/25',\n",
       "     'BookedDate': '30/07/25',\n",
       "     'CounterParty': None,\n",
       "     'Amount': '0,00 AED'}],\n",
       "   'BankReference': '303000 / 3013086001869',\n",
       "   'TransactionType': '30 Miscellaneous transactions'},\n",
       "  {'section': '210',\n",
       "   'OpeningBalance': '29/07/25 0,00 AED',\n",
       "   'ClosingBalance': '29/07/25 0,00 AED',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '29/07/25',\n",
       "     'BookedDate': '29/07/25',\n",
       "     'CounterParty': None,\n",
       "     'Amount': '0,00 AED'}],\n",
       "   'BankReference': '3039000 / 3012986001859',\n",
       "   'TransactionType': '30 Miscellaneous transactions'},\n",
       "  {'section': '209',\n",
       "   'OpeningBalance': '28/07/25 0,00 AED',\n",
       "   'ClosingBalance': '28/07/25 0,00 AED',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '28/07/25',\n",
       "     'BookedDate': '28/07/25',\n",
       "     'CounterParty': None,\n",
       "     'Amount': '0,00 AED'}],\n",
       "   'BankReference': '30390 / 3012886001593',\n",
       "   'TransactionType': '30 Miscellaneous transactions'},\n",
       "  {'section': '208',\n",
       "   'OpeningBalance': '27/07/25 0,00 AED',\n",
       "   'ClosingBalance': '27/07/25 0,00 AED',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '27/07/25',\n",
       "     'BookedDate': '27/07/25',\n",
       "     'CounterParty': None,\n",
       "     'Amount': '0,00 AED'}],\n",
       "   'BankReference': '30390 / 0186001889',\n",
       "   'TransactionType': '30 Miscellaneous transactions'},\n",
       "  {'section': '211',\n",
       "   'OpeningBalance': '30/07/25 0,00 AUD',\n",
       "   'ClosingBalance': '30/07/25 0,00 AUD',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '30/07/25',\n",
       "     'BookedDate': '30/07/25',\n",
       "     'CounterParty': 'BBRUBE - CDB',\n",
       "     'Amount': '0,00 AUD'}],\n",
       "   'BankReference': '30390 / 3013086001',\n",
       "   'TransactionType': '30 Miscellaneous transactions'},\n",
       "  {'section': '210',\n",
       "   'OpeningBalance': '29/07/25 0,00 AUD',\n",
       "   'ClosingBalance': '29/07/25 0,00 AUD',\n",
       "   'EndOfDayInformation': None,\n",
       "   'Transactions': [{'ValueDate': '29/07/25',\n",
       "     'BookedDate': '29/07/25',\n",
       "     'CounterParty': None,\n",
       "     'Amount': '0,00 AUD'}],\n",
       "   'BankReference': '3039000 / 3012986001859',\n",
       "   'TransactionType': '30 Miscellaneous transactions'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_path = \"/Volumes/workspace/default/pdfvolume/IngStmtPdfWork.pdf\"  # change if needed\n",
    "\n",
    "# ---------- Extract the structured data using pipelien ------------------\n",
    "doc = extract_structured_pdf(pdf_path, use_ocr=True, dpi=600, lang=\"eng\")\n",
    "display(doc)\n",
    "#print(json.dumps(doc, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac0bfee-499d-422d-8510-f7c9ded6ded8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MutliCurrencyWithAI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}